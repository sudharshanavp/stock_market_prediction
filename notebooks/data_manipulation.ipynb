{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDzsTj-5hbiv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY08R3U_hbiw"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlmUWM2Ahbiy"
      },
      "outputs": [],
      "source": [
        "directory = \"../datasets/stock\"\n",
        "df1 = pd.read_csv(directory+\"/old_data/\"+\"ADANIPORTS.csv\")\n",
        "drop_list = ['Turnover','Trades','Deliverable Volume','%Deliverble']\n",
        "df1 = df1.drop(drop_list, axis=1)\n",
        "df1['Date'] = pd.to_datetime(df1.Date)\n",
        "last_index = df1.index[-1] + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0cNmzmWhbiz"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv(directory+\"/new_data/\"+\"ADANIPORTS_1.csv\")\n",
        "drop_list = ['52W H ','52W L ','VALUE ','No of trades ']\n",
        "df2 = df2.sort_index(ascending=False)\n",
        "df2.insert(1, \"Symbol\", \"ADANIPORTS\")\n",
        "col = df2['PREV. CLOSE ']\n",
        "df2 = df2.drop('PREV. CLOSE ',axis=1)\n",
        "df2.insert(3, 'PREV. CLOSE ', col)\n",
        "df2 = df2.drop(drop_list,axis=1)\n",
        "rows = np.array(sorted(df2.axes[0]))\n",
        "rows = last_index+rows\n",
        "df2.index = rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yh9h0_bahbi0"
      },
      "outputs": [],
      "source": [
        "df2.columns = df1.columns\n",
        "df2['Date'] = pd.to_datetime(df2.Date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2P7QyyHhbi1"
      },
      "outputs": [],
      "source": [
        "final_df = df1.append(df2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCxbySHkhbi2"
      },
      "source": [
        "## Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXMFnHaZhbi2"
      },
      "outputs": [],
      "source": [
        "def wrangler(file):\n",
        "    directory = \"../data/raw/stock\"\n",
        "    df1 = pd.read_csv(directory+\"/old_data/\"+file+\".csv\")\n",
        "    drop_list = ['Turnover','Trades','Deliverable Volume','%Deliverble']\n",
        "    df1 = df1.drop(drop_list, axis=1)\n",
        "    df1['Date'] = pd.to_datetime(df1.Date)\n",
        "    last_index = df1.index[-1] + 1\n",
        "    \n",
        "    df2 = pd.read_csv(directory+\"/new_data/\"+file+\".csv\")\n",
        "    drop_list = ['52W H ','52W L ','VALUE ','No of trades ']\n",
        "    df2 = df2.sort_index(ascending=False)\n",
        "    df2.insert(1, \"Symbol\", file)\n",
        "    col = df2['PREV. CLOSE ']\n",
        "    df2 = df2.drop('PREV. CLOSE ',axis=1)\n",
        "    df2.insert(3, 'PREV. CLOSE ', col)\n",
        "    df2 = df2.drop(drop_list,axis=1)\n",
        "    rows = np.array(sorted(df2.axes[0]))\n",
        "    rows = last_index+rows\n",
        "    df2.index = rows\n",
        "    \n",
        "    df2.columns = df1.columns\n",
        "    df2['Date'] = pd.to_datetime(df2.Date)\n",
        "    \n",
        "    final_df = df1.append(df2)\n",
        "    final_df.to_csv(r'../data/processed/stocks/'+file+'.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbUkDDrzhbi4"
      },
      "outputs": [],
      "source": [
        "directory = \"../data/raw/stock\"\n",
        "stock_list = sorted(os.listdir(\"../data/raw/stock/old_data\"))\n",
        "stock_list = [string.removesuffix('.csv') for string in stock_list]\n",
        "stock_list.remove('NIFTY50_all')\n",
        "stock_list.remove('stock_metadata')\n",
        "stock_list = stock_list[9:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIDAKOi8hbi5"
      },
      "outputs": [],
      "source": [
        "for filename in stock_list:\n",
        "    wrangler(filename)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing google colab"
      ],
      "metadata": {
        "id": "HQikd5jyheVw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "96c29df3c9882678c9224b48ef6832271283dc1a6410b0d31dfff6ccd69c0f45"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('data_science')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "data_manipulation.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}